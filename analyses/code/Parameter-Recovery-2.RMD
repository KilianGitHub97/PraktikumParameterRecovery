---
title: "Parameter Recovery GCM"
author: "Jana Jarecki & Kilian Sennrich"
date: "22 7 2020"
output: 
  html_document:
    theme: united
    toc: true
    toc_float: true
---
```{r, echo=TRUE, results="hide", message=FALSE}
#Libraries
pkgs <- c("data.table",
          "tidyverse",
          "Hmisc",
          "psych")

lapply(pkgs, library, character.only = TRUE)
```

```{r, echo=TRUE, results="hide", message=FALSE}
#Data // l = long; w = wide
data.l <- readRDS("../../data/raw/recovery_results.RDS")
data.l <- data.l[convergence != 1][, convergence := NULL]
data.w <- dcast(data = data.l,
                formula = run + discount + nblock + type + row ~ names,
                value.var = c("par", "true_par"))
```

There are 31 cases, where the GCM could not find optimal free parameters.

## 1. What interdependencies can be found between the variables?

In the following, I compile a correlation matrix to see, whether there are interdependencies between different variables. Significant correlation indicates some kind of systematic influence between the two variables involved. First, "row" and "run" columns are deleted from the data frame, that is because "run" is not expected to have significant influence and because all information of the "row" column if fully covered by the "true_par_lambda" and "true_par_tau" columns. Second, Spearman correlation is used to compile the correlation matrix. The nonparametric method is used, since not all the data is expected to meet criteria for pearson correlation. Third, correlation matrix is transformed to be in a more accessible format. Fourth, significant p-values are filtered. Knowing interdependencies gathers evidence for the decision to plot and test data either marginalized or conditioned.

```{r, echo=TRUE, results="hide", message=FALSE}
#Prepare data for correlation matrix
data.w.cor <- data.w[, -c("row", "run")]

#correlation matrix to check for interdependencies between the variables. Nonparametric method is used, since data did not meet criteria for pearson
cormat <- rcorr(as.matrix(data.w.cor), type = "spearman")
cormat.r <- as.data.frame(t(cormat$r))
cormat.p <- as.data.frame(cormat$P)
data.cor <-data.table(Var1 = rownames(cormat.r)[row(cormat.r)[upper.tri(cormat.r)]], 
                      Var2 = colnames(cormat.r)[col(cormat.r)[upper.tri(cormat.r)]], 
                      corr=round(cormat.r[upper.tri(cormat.r)],4),
                      p = round(cormat.p[upper.tri(cormat.p)],4))

#filter relevant values
data.cor.rel <- data.cor[corr != 0 & corr != 1 & corr != -1 & p < 0.05]
```

**Graphical analysis of the recovery of all parameters**

For every parameter, dependencies on other variables will be checked. Depending on this, the plots are designed as meaningful as possible. 

### graph 1

```{r, echo=TRUE}
#recovery of b0
data.cor.rel[Var1 == "par_b0" | Var2 == "par_b0"]

data.w.b0 <- data.w %>% 
  group_by(type, true_par_tau) %>% 
  mutate(med_b0 = median(par_b0))

ggplot(data = data.w.b0,
       mapping = aes(y = par_b0)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_b0), color = "red") +
  geom_hline(aes(yintercept = med_b0), color="blue", linetype="dashed")+
  facet_grid(true_par_tau ~ type)+
  theme_minimal()
```

### graph 2

```{r, echo=TRUE}

#recovery of b1
data.cor.rel[Var1 == "par_b1" | Var2 == "par_b1"]

data.w.b1 <- data.w %>% 
  group_by(type, true_par_tau) %>% 
  mutate(med_b1 = median(par_b1))

ggplot(data = data.w.b1,
       mapping = aes(y = par_b1)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_b1), color = "red") +
  geom_hline(aes(yintercept = med_b1), color="blue", linetype="dashed")+
  facet_grid(true_par_tau ~ type) +
  theme_minimal()
```

### graph 3

```{r, echo=TRUE}
#recovery of size
data.cor.rel[Var1 == "par_size" | Var2 == "par_size"]

data.w.size <- data.w %>% 
  group_by(type) %>% 
  mutate(med_size = median(par_size))

ggplot(data = data.w.size,
       mapping = aes(y = par_size)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_size), color = "red") +
  geom_hline(aes(yintercept = med_size, group = type), color="blue", linetype="dashed")+
  facet_wrap(~type)+
  theme_minimal()
```

###graph 4

```{r, echo=TRUE}
#recovery of color
data.cor.rel[Var1 == "par_color" | Var2 == "par_color"]

data.w.color <- data.w %>% 
  group_by(nblock, true_par_lambda, true_par_tau) %>% 
  mutate(med_color = median(par_color))

ggplot(data = data.w.color,
       mapping = aes(y = par_color)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_color), color = "red") +
  geom_hline(aes(yintercept = med_color), color="blue", linetype="dashed")+
  facet_grid(true_par_lambda ~ nblock + true_par_tau) +
  theme_minimal()
```

### graph 5

```{r, echo=TRUE}

#recovery of shape
data.cor.rel[Var1 == "par_shape" | Var2 == "par_shape"]

data.w.shape <- data.w %>%
  group_by(true_par_tau, true_par_lambda, type) %>%
  mutate(med_shape = median(par_shape))

ggplot(data = data.w.shape,
       mapping = aes(y = par_shape)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_shape), color = "red") +
  geom_hline(aes(yintercept = med_shape), color="blue", linetype="dashed") +
  facet_grid(type ~ true_par_tau + true_par_lambda) +
  theme_minimal()
```

### graph 6

```{r, echo=TRUE}
#recovery of lambda
data.cor.rel[Var1 == "par_lambda" | Var2 == "par_lambda"]

data.w.lambda <- data.w %>%
  group_by(true_par_lambda, true_par_tau, type) %>%
  mutate(med_lambda = median(par_lambda))
         
ggplot(data = data.w.lambda,
       mapping = aes(y = par_lambda)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_lambda), color = "red") +
  geom_hline(aes(yintercept = med_lambda), color="blue", linetype="dashed")+
  facet_grid(true_par_lambda + true_par_tau ~ type)+
  theme_minimal()
```

#graph 7

```{r, echo=TRUE}
#recovery of tau
data.cor.rel[Var1 == "par_tau" | Var2 == "par_tau"]

data.w.tau <- data.w %>% 
  group_by(true_par_tau, nblock) %>% 
  mutate(med_tau = median(par_tau))
  
ggplot(data = data.w.tau,
       mapping = aes(y = par_tau)) +
  geom_histogram(bins = 100) +
  geom_hline(aes(yintercept = true_par_tau), color = "red") +
  geom_hline(aes(yintercept = med_tau), color="blue", linetype="dashed")+ 
  facet_grid(nblock ~ true_par_tau) +
  theme_minimal()
```

```{r, echo=TRUE, results="hide", message=FALSE}
#subset data for further testing
cormat.test <- data.table(data.w[, c("par_tau", "true_par_tau" , "discount", "nblock", "type", "true_par_lambda")])
```

## 2. Impact of omitting the first 3 and 8 rows on recovering tau

According to the GCM, omitting the first 3 or 8 rows should lead to better recovery of the tau parameter. Reason being, that the machine learning algorithm does not make accurate decisions on early rows of training.  To further test the effect of omitting the aforementioned rows, spearman correlation coefficients will be compared in a correlation test. Since nblock seems to have impact on par_tau (although correlation is small and could have emerged due to randomness), separate testing for nblock = 30 and nblock = 100 is advised.

```{r, echo=TRUE}
# decision between marginalized vs. conditionized testing
data.cor.rel[Var1 == "par_tau" | Var2 == "par_tau"] #influence on tau
data.cor.rel[Var1 == "discount" | Var2 == "discount"]#influence on discount
data.cor.rel[Var1 == "true_par_tau" | Var2 == "true_par_tau"] #influence on true tau
```

```{r, echo=TRUE, results="hide", message=FALSE}
#subset discounts
cormat.test.d0n30 <- cormat.test[discount == 0 & nblock == 30]
cormat.test.d8n30 <- cormat.test[discount == 8 & nblock == 30]
cormat.test.d0n100 <- cormat.test[discount == 0 & nblock == 100]
cormat.test.d8n100 <- cormat.test[discount == 8 & nblock == 100]
```

```{r, echo=TRUE}
#correlation test for nblock = 30
r.test(n = nrow(cormat.test.d0n30),
       n2 = nrow(cormat.test.d8n30),
       r12 = cor(cormat.test.d0n30$par_tau,
                 cormat.test.d0n30$true_par_tau,
                 method = "spearman"),
       r34 = cor(cormat.test.d8n30$par_tau,
                 cormat.test.d8n30$true_par_tau,
                 method = "spearman"))

#correlation test for nblock = 100
r.test(n = nrow(cormat.test.d0n100),
       n2 = nrow(cormat.test.d8n100),
       r12 = cor(cormat.test.d0n100$par_tau,
                 cormat.test.d0n100$true_par_tau,
                 method = "spearman"),
       r34 = cor(cormat.test.d8n100$par_tau,
                 cormat.test.d8n100$true_par_tau,
                 method = "spearman"))
```

**Graphical evaluation**

### graph 8

```{r, echo=TRUE}
#violin plots for discount per par_tau (Ev mÃ¼ssen wir noch konditionieren)
ggplot(data = data.w,
       mapping = aes(x = as.factor(discount),
                     y = par_tau)) +
  geom_violin(width = 0.9) +
  stat_summary(fun = "median", 
               geom = "point") +
  geom_line(aes(x = discount, 
                y = true_par_tau), 
            color = "red", 
            size = 0.5) +
  facet_grid(nblock ~ true_par_tau)+
  ylim(0, 10) +
  xlab("Discount") +
  ylab("Tau") +
  theme_minimal()
```

### graph 9

```{r, echo=TRUE}
# line plot
ggplot(data = data.w,
       mapping = aes(x = true_par_tau,
                     y = par_tau)) +
  geom_point(aes(x = true_par_tau,
                 y = par_tau),
             alpha = 1 / 20) +
  geom_line(aes(x = true_par_tau,
                y = true_par_tau),
            color = "red") +
  stat_summary(aes(group = discount),
               fun = median,
               geom = "line",
               color = c(rep("green", 6), #discount = 0
                         rep("blue", 6),  #discount = 8
                         rep("green", 6), #discount = 0
                         rep("blue", 6)   #discount = 8
                         ))+
  facet_wrap(~nblock) +
  ylim(0,10) +
  xlab("True tau") +
  ylab("Median of estimated tau") +
  theme_minimal()
```


## 3. Impact of training with multiple blocks on recovery of tau

According to the GCM, the more repetitive blocks a subject will be able to learn with, the better the categorization accuracy should get. Therefore, with increasing blocks, a better recovery is expected. There are no significant dependencies on nblock. Therefore, its ok to not further subset the data. 

```{r, echo=TRUE}
# decision between marginalized vs. conditionized testing
data.cor.rel[Var1 == "nblock" | Var2 == "nblock"]#influence on nblock
```

```{r, echo=TRUE, results="hide", message=FALSE}
#subset nblock
cormat.test.n30 <- cormat.test[nblock == 30]
cormat.test.n100 <- cormat.test[nblock == 100]
```

```{r, echo=TRUE}
#correlation test
r.test(n = nrow(cormat.test.n30),
       n2 = nrow(cormat.test.n100),
       r12 = cor(cormat.test.n30$par_tau,
                 cormat.test.n30$true_par_tau,
                 method = "spearman"),
       r34 = cor(cormat.test.n100$par_tau,
                 cormat.test.n100$true_par_tau,
                 method = "spearman"))
```

**Graphical analysis**

### graph 10

```{r, echo=TRUE}
#violin plots for nblock per par_tau
ggplot(data = data.w,
       mapping = aes(x = as.factor(nblock),
                     y = par_tau)) +
  geom_violin(width = 0.9) +
  stat_summary(fun = "median", 
               geom = "point") +
  geom_line(aes(x = par_tau, 
                y = true_par_tau), 
            color = "red", 
            size = 0.5) +
  facet_wrap(~true_par_tau)+
  ylim(0, 10) +
  xlab("nblock") +
  ylab("Tau") +
  theme_minimal()
```

### graph 11

```{r, echo=TRUE}
# line plot
ggplot(data = data.w,
       mapping = aes(x = true_par_tau,
                     y = par_tau)) +
  geom_point(aes(x = true_par_tau,
                 y = par_tau),
             alpha = 1 / 20) +
  geom_line(aes(x = true_par_tau,
                y = true_par_tau),
            color = "red") +
  stat_summary(aes(group = nblock),
               fun = median,
               geom = "line",
               color = c(rep("green", 6),  #nblock = 30
                         rep("blue", 6)    #nblock = 100
                         ))+
  ylim(0,10) +
  xlab("True tau") +
  ylab("Median of estimated tau") +
  theme_minimal()
```

## 4. ability of the GCM to grasp the difficulty of the categories on the tau parameter

Shepard suggests, that of 70 possible combinations of elements characterized by 3 dimensions in psychological space, 6 basic types can be derived. The types vary in the dimensions, a subject has to focus on, and therefore can be put into an order of difficulty.Shepard suggests the following order of difficulty:  I < II < ( I I I , IV, V) < VI. If the GCM function works, depending on the type, goodness of recovery of tau paramter should imitate the suggested order. No significant dependency on type can be found.

```{r, echo=TRUE}
# decision between marginalized vs. conditionized testing
data.cor.rel[Var1 == "type" | Var2 == "type"]#influence on type
```

```{r, echo=TRUE, results="hide", message=FALSE}
#subset types
cormat.test.30.1 <- cormat.test[nblock == 30 & type == 1]
cormat.test.30.2 <- cormat.test[nblock == 30 & type == 2]
cormat.test.30.3 <- cormat.test[nblock == 30 & type == 3]
cormat.test.30.4 <- cormat.test[nblock == 30 & type == 4]
cormat.test.30.5 <- cormat.test[nblock == 30 & type == 5]
cormat.test.30.6 <- cormat.test[nblock == 30 & type == 6]

cormat.test.100.1 <- cormat.test[nblock == 100 & type == 1]
cormat.test.100.2 <- cormat.test[nblock == 100 & type == 2]
cormat.test.100.3 <- cormat.test[nblock == 100 & type == 3]
cormat.test.100.4 <- cormat.test[nblock == 100 & type == 4]
cormat.test.100.5 <- cormat.test[nblock == 100 & type == 5]
cormat.test.100.6 <- cormat.test[nblock == 100 & type == 6]
```

```{r, echo=TRUE}
#calculate correlation test for all expressions of type
rtest.results <- list()
cormat.res <- list()


l = 1

for (i in 1:6) {
  for (j in 1:6) {
    for (k in c(30, 100)){
      for (m in c(30, 100)) {

    #select components to apply r.test
    component1 <- get(paste("cormat.test", k, i, sep = "."))
    component2 <- get(paste("cormat.test", m, j, sep = "."))
    
    #calculate r.test and save it to rtest.results
    rtest.results[[l]] <- r.test(n = nrow(component1),
                                 n2 = nrow(component2),
                                 r12 = cor(component1$par_tau,
                                           component1$true_par_tau,
                                           method = "spearman"),
                                 r34 = cor(component2$par_tau,
                                           component2$true_par_tau,
                                           method = "spearman"))
    
    #draw compatible list to later convert to data.table
    cormat.res[[l]] <-  data.table(
        component1 = paste0("type=", i),
        component2 = paste0("type=", j),
        nblock_comp1 = k,
        nblock_comp2 = m,
        p_value = round(rtest.results[[l]]$p, 4),
        z_score = round(rtest.results[[l]]$z, 4)
    )
   
      l = l + 1
      }
    }
  }
}
cormat.res <- rbindlist(cormat.res)
cormat.res <- cormat.res[z_score != 0]

cormat.res.rel <- cormat.res[p_value < 0.05]

print(cormat.res.rel)
```

**Graphical analysis**

### graph 12

```{r, echo=TRUE}
#violin plots for par_tau per type
ggplot(data = data.w,
       mapping = aes(x = as.factor(type),
                     y = par_tau)) +
  geom_violin(width = 0.9) +
  stat_summary(fun = "median", 
               geom = "point") +
  geom_line(aes(x = par_tau, 
                y = true_par_tau), 
            color = "red", 
            size = 0.5) +
  facet_grid(nblock ~ true_par_tau)+
  ylim(0, 10) +
  xlab("type") +
  ylab("Tau") +
  theme_minimal()
```

### graph 13

```{r, echo=TRUE}
# line plot
ggplot(data = data.w,
       mapping = aes(x = true_par_tau,
                     y = par_tau)) +
  geom_point(aes(x = true_par_tau,
                 y = par_tau),
             alpha = 1 / 20) +
  geom_line(aes(x = true_par_tau,
                y = true_par_tau),
            color = "red") +
  stat_summary(aes(group = type),
               fun = median,
               geom = "line",
               color = c(rep("blue", 144)
                         ))+
  facet_grid(nblock + discount ~ type)+
  ylim(0,10) +
  xlab("True tau") +
  ylab("Median of estimated tau") +
  theme_minimal()
```

## 5. Influence of Lambda on the recovery of Tau

Lambda, the speed of learning (sensitivity) is considered to have a positive impact on the recovery of Tau. When a person learns quicker, the recovery of the prabability of implementing an action should be better especially with bigger Tau values.No significant dependencies on true_par_lambda can be found. 

```{r, echo=TRUE}
# decision between marginalized vs. conditionized testing
data.cor.rel[Var1 == "true_par_lambda" | Var2 == "true_par_lambda"]#influence on discount
```

```{r, echo=TRUE, results="hide", message=FALSE}
#subset discounts
cormat.test.lam1.30 <- cormat.test[nblock == 30 & true_par_lambda == 1]
cormat.test.lam5.30 <- cormat.test[nblock == 30 & true_par_lambda == 5]
cormat.test.lam1.100 <- cormat.test[nblock == 100 & true_par_lambda == 1]
cormat.test.lam5.100 <- cormat.test[nblock == 100 & true_par_lambda == 5]
```

```{r, echo=TRUE}
#correlation test
r.test(n = nrow(cormat.test.lam1.30),
       n2 = nrow(cormat.test.lam5.30),
       r12 = cor(cormat.test.lam1.30$par_tau,
                 cormat.test.lam1.30$true_par_tau,
                 method = "spearman"),
       r34 = cor(cormat.test.lam5.30$par_tau,
                 cormat.test.lam5.30$true_par_tau,
                 method = "spearman"))

r.test(n = nrow(cormat.test.lam1.100),
       n2 = nrow(cormat.test.lam5.100),
       r12 = cor(cormat.test.lam1.100$par_tau,
                 cormat.test.lam1.100$true_par_tau,
                 method = "spearman"),
       r34 = cor(cormat.test.lam5.100$par_tau,
                 cormat.test.lam5.100$true_par_tau,
                 method = "spearman"))
```

**Graphical analysis**

### graph 14

```{r, echo=TRUE}
#violin plots for true lambda per par_tau
ggplot(data = data.w,
       mapping = aes(x = as.factor(true_par_lambda),
                     y = par_tau)) +
  geom_violin(width = 0.9) +
  stat_summary(fun = "median", 
               geom = "point") +
  geom_line(aes(x = par_tau, 
                y = true_par_tau), 
            color = "red", 
            size = 0.5) +
  facet_grid(nblock ~ true_par_tau)+
  ylim(0, 10) +
  xlab("Lambda") +
  ylab("Tau") +
  theme_minimal()
```

### graph 15

```{r, echo=TRUE}
# line plot
ggplot(data = data.w,
       mapping = aes(x = true_par_tau,
                     y = par_tau)) +
  geom_point(aes(x = true_par_tau,
                 y = par_tau),
             alpha = 1 / 20) +
  geom_line(aes(x = true_par_tau,
                y = true_par_tau),
            color = "red") +
  stat_summary(aes(group = true_par_lambda),
               fun = median,
               geom = "line",
               color = c(rep("green", 6),  #lambda = 1
                         rep("blue", 6),   #lambda = 5
                         rep("green", 6),  #lambda = 1
                         rep("blue", 6)    #lambda = 5
                         ))+
  facet_wrap(~nblock)+
  ylim(0,10) +
  xlab("True tau") +
  ylab("Median of estimated tau") +
  theme_minimal()
```
